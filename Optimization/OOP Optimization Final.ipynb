{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from hmmlearn import hmm\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import cvxpy as cp\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "random.seed(50)\n",
    "\n",
    "## Additions below\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Main\n",
    "\n",
    "\n",
    "#Set up Data\n",
    "price_data = pd.read_csv(\"../Data/small_universe.csv\", index_col='Date').fillna(method=\"bfill\")\n",
    "rf = price_data[\"10 YR\"]\n",
    "universe=['ETN', 'AME', 'AAL', 'CHRW', 'ABT', 'AMGN', 'VRTX', 'ALGN', 'AAPL', 'ADBE', 'AMD', 'ADS', 'T', 'CMCSA', 'ATVI', 'CHTR', 'AMZN', 'F', 'DG', 'CMG', 'DUK', 'LNT', 'AES', 'FE', 'C', 'BAC', 'CBOE', 'RE', 'APD', 'FMC', 'BLL', 'CF', 'DRE', 'BXP', 'EQIX', 'CCI', 'CL', 'KMB', 'KR', 'STZ', 'CVX', 'XOM', 'COG', 'APA']\n",
    "data = Data(price_data, rf,universe)\n",
    "\n",
    "#Set up Portfolio\n",
    "port=Portfolio(data)\n",
    "\n",
    "#Set up Variables\n",
    "start_date = \"2006-12-31\"\n",
    "end_date = \"2020-11-26\"\n",
    "#1 year lookback\n",
    "lookback = 12 \n",
    "lookahead = 1\n",
    "annual_ret=0.1\n",
    "lam = annual_ret**(1/12)-1\n",
    "trans_coeff = 0.1\n",
    "holding_coeff = 0.1\n",
    "conf_level = 0.7\n",
    "\n",
    "#Set up constraints\n",
    "constr_list = [\"asset_limit_cardinality\"]\n",
    "constr_model = Constraints(constr_list)\n",
    "\n",
    "#Set up cost models\n",
    "cost_model = Costs(trans_coeff, holding_coeff)\n",
    "cost_model.replicate_cost_coeff(num_stocks, lookahead)\n",
    "\n",
    "opt_model = Model(lam)\n",
    "risk_model = Risks(\"rect\", conf_level)\n",
    "\n",
    "regress_weighting = [0,0,0,0]\n",
    "factor_model = FactorModel(lookahead, lookback, regress_weighting)\n",
    "\n",
    "back_test = Backtest(start_date, end_date, lookback, lookahead)\n",
    "back_test.run(data_set, port, factor_model, opt_model, constr_model, cost_model, risk_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definitions Data/Portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    #Anything Data Related\n",
    "    def __init__(self, stock_prices, risk_free, universe=None,factor_type='PCA', period='M'):\n",
    "        #TO-DO: Add initialization of market cap\n",
    "        \n",
    "        if not universe:\n",
    "            universe = stock_prices.columns\n",
    "            \n",
    "        if type(universe[0]) == int:\n",
    "            self.stock_prices = stock_prices.iloc[:,universe]\n",
    "\n",
    "        else:\n",
    "            self.stock_prices = stock_prices[universe]\n",
    "        \n",
    "        self.risk_free = risk_free\n",
    "        self.risk_free.index = pd.to_datetime(self.risk_free.index)\n",
    "        self.risk_free = self.risk_free.resample(period).last()\n",
    "        self.stock_prices.index= pd.to_datetime(self.stock_prices.index)\n",
    "        self.stock_returns=self.get_stock_returns(period)\n",
    "        self.factor_returns= self.get_factor_returns(factor_type)\n",
    " \n",
    "        return\n",
    "    \n",
    "    def get_stock_returns(self, period='M'):\n",
    "        price = self.stock_prices.resample(period).last()\n",
    "\n",
    "        # Calculate the percent change\n",
    "        ret_data = price.pct_change()[1:]\n",
    "\n",
    "        # Convert from series to dataframe\n",
    "        ret_data = pd.DataFrame(ret_data)\n",
    "\n",
    "        return ret_data\n",
    "\n",
    "    def get_factor_returns(self, factor_type='PCA', period='M'):\n",
    "        if factor_type == 'CAPM':\n",
    "         \n",
    "            return self.get_CAPM_returns(period)\n",
    "        \n",
    "        elif factor_type == 'FF':\n",
    "       \n",
    "            return self.get_FF_returns(period)\n",
    "            \n",
    "        elif factor_type == 'Carhart':\n",
    "           \n",
    "            return self.get_Carhart_returns(period)\n",
    "            \n",
    "        elif factor_type == 'PCA':\n",
    "           \n",
    "            return self.get_PCA_returns(period)\n",
    "        \n",
    "        else:\n",
    "            print(\"Invalid input: Please select one of the following factor types: CAPM, FF, Carhart or PCA.\")\n",
    "        \n",
    "        return   \n",
    "    \n",
    "    def get_FF_returns(self, period='M'):\n",
    "        ff_url = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_CSV.zip\"    \n",
    "        # Download the file and save it  \n",
    "        urllib.request.urlretrieve(ff_url,'fama_french.zip')\n",
    "        zip_file = zipfile.ZipFile('fama_french.zip', 'r')    \n",
    "        # Extact the file data\n",
    "        zip_file.extractall()\n",
    "        zip_file.close()    \n",
    "        ff_factors = pd.read_csv('F-F_Research_Data_Factors.csv', skiprows = 3, index_col = 0)   \n",
    "        # Skip null rows\n",
    "        ff_row = ff_factors.isnull().any(1).to_numpy().nonzero()[0][0]\n",
    "\n",
    "        # Read the csv file again with skipped rows\n",
    "        ff_factors = pd.read_csv('F-F_Research_Data_Factors.csv', skiprows = 3, nrows = ff_row, index_col = 0)\n",
    "\n",
    "        # Format the date index\n",
    "        ff_factors.index = pd.to_datetime(ff_factors.index, format= '%Y%m')\n",
    "\n",
    "        # Format dates to end of month\n",
    "        ff_factors.index = ff_factors.index + pd.offsets.MonthEnd()\n",
    "\n",
    "        # Resample the data to correct frequency\n",
    "        ff_factors = ff_factors.resample(period).last()\n",
    "\n",
    "        # Convert from percent to decimal\n",
    "        ff_factors = ff_factors.apply(lambda x: x/ 100)\n",
    "\n",
    "        return ff_factors\n",
    "    \n",
    "    def get_CAPM_returns(self, period='M'):\n",
    "        ff_factors = self.get_FF_returns(period)\n",
    "        \n",
    "        # Remove the unnecessary factors\n",
    "        capm_factors = ff_factors.iloc[:, 0]\n",
    "        \n",
    "        return capm_factors\n",
    "    \n",
    "    def get_Carhart_returns(self, period='M'):\n",
    "        ff_factors = self.get_FF_returns(period)\n",
    "\n",
    "        # Get the momentum factor\n",
    "        momentum_url = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Momentum_Factor_CSV.zip\"\n",
    "\n",
    "        # Download the file and save it  \n",
    "        urllib.request.urlretrieve(momentum_url,'momentum.zip')\n",
    "        zip_file = zipfile.ZipFile('momentum.zip', 'r')\n",
    "\n",
    "        # Extact the file data\n",
    "        zip_file.extractall()\n",
    "        zip_file.close()\n",
    "\n",
    "        momentum_factor = pd.read_csv('F-F_Momentum_Factor.csv', skiprows = 13, index_col = 0)\n",
    "\n",
    "        # Skip null rows\n",
    "        row = momentum_factor.isnull().any(1).to_numpy().nonzero()[0][0]\n",
    "\n",
    "        # Read the csv file again with skipped rows\n",
    "        momentum_factor = pd.read_csv('F-F_Momentum_Factor.csv', skiprows = 13, nrows = row, index_col = 0)\n",
    "\n",
    "        # Format the date index\n",
    "        momentum_factor.index = pd.to_datetime(momentum_factor.index, format= '%Y%m')\n",
    "\n",
    "        # Format dates to end of month\n",
    "        momentum_factor.index = momentum_factor.index + pd.offsets.MonthEnd()\n",
    "\n",
    "         # Resample the data to correct frequency\n",
    "        momentum_factor = momentum_factor.resample(period).last()\n",
    "\n",
    "        # Convert from percent to decimal\n",
    "        momentum_factor = momentum_factor.apply(lambda x: x/ 100)\n",
    "\n",
    "        # Combine to create the carhart_factors\n",
    "        carhart_factors = pd.concat([ff_factors, momentum_factor], axis=1).dropna()\n",
    "\n",
    "        return carhart_factors\n",
    "    \n",
    "    def get_PCA_returns(self, period='M'):\n",
    "        exRets = self.get_stock_returns(period=\"D\")\n",
    "        num_stocks = len(exRets.columns)\n",
    "        returns_mat = exRets.to_numpy()\n",
    "        n_dates = returns_mat.shape[0]\n",
    "        n_assets = returns_mat.shape[1]\n",
    "        \n",
    "        demeaned = (returns_mat - returns_mat.mean(axis=0)).transpose()\n",
    "        sigma = 1/(n_dates - 1)*np.matmul(demeaned,demeaned.transpose())\n",
    "        eigval, eigvec = np.linalg.eig(sigma)\n",
    "        \n",
    "        principal_components = np.matmul(eigvec.transpose(),demeaned).transpose()\n",
    "        pca_factors = np.real(principal_components[:,0:100])\n",
    "        \n",
    "        pca_df = pd.DataFrame(pca_factors, index = exRets.index, columns = [str(i) for i in range(num_stocks)])\n",
    "        pca_df = pca_df.resample(period).last()\n",
    "        \n",
    "        return pca_df\n",
    "    \n",
    "    def get_index_from_date(self, date_index_df, date):\n",
    "        return date_index_df.index.get_loc(date)\n",
    "    \n",
    "    def get_lookback_data(self, date_index_df, date, lookback):\n",
    "        end_idx= self.get_index_from_date(date_index_df, date)\n",
    "        return date_index_df.iloc[end_idx-lookback:end_idx]      \n",
    "    \n",
    "    def get_num_stocks(self):\n",
    "        return len(self.stock_returns.columns)\n",
    "\n",
    "    \n",
    "class Portfolio:\n",
    "    #Anything Portfolio related: weights, returns, date-stamped\n",
    "    def __init__(self, data):       \n",
    "        num_stocks=data.get_num_stocks()\n",
    "        self.weights= np.array([[0]*num_stocks + [1]]) # 0 weight on stock\n",
    "        self.returns= np.array([])\n",
    "        self.dates= []\n",
    "        return\n",
    "        \n",
    "    def update_weights(self, new_weights):\n",
    "        \n",
    "        new_weights = np.expand_dims(new_weights, axis=0)\n",
    "        self.weights = np.append(self.weights, new_weights, axis=0)\n",
    "        return\n",
    "     \n",
    "    def update_returns(self, new_returns):\n",
    "        self.returns=np.append(self.returns, new_returns)\n",
    "        return\n",
    "\n",
    "    def update_dates(self, new_dates):\n",
    "       \n",
    "        self.dates.append(new_dates)\n",
    "        return\n",
    "        \n",
    "    def get_Sharpe(self, data):\n",
    "        risk_free = data.risk_free\n",
    "        recent_date = self.dates[-1]\n",
    "        sigma = np.std(self.returns - np.array(risk_free.loc[self.dates]))\n",
    "        sharpe_ratio = ((np.prod(1+self.returns)-1) - np.array(risk_free.loc[recent_date]))/sigma\n",
    "        return sharpe_ratio\n",
    "        \n",
    "    def plot(self):\n",
    "        port_cumu_returns = np.array([x+1 for x in self.returns]).cumprod()\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(self.dates, port_cumu_returns)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Cumulative Return\")\n",
    "        plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definitions: Cost/Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Costs:\n",
    "    def __init__(self, trans_coeff, holding_coeff):\n",
    "        self.holding_cost = 0\n",
    "        self.trans_cost = 0\n",
    "        self.trans_coeff = trans_coeff\n",
    "        self.holding_coeff = holding_coeff\n",
    "        return\n",
    "        \n",
    "    def replicate_cost_coeff(self, num_stocks, lookahead):\n",
    "        trans_cost_repl = np.ones((num_stocks,lookahead))\n",
    "        holding_cost_repl = np.ones((num_stocks, lookahead))\n",
    "        self.trans_coeff = trans_cost_repl*self.trans_coeff\n",
    "        self.holding_coeff = holding_cost_repl*self.holding_coeff\n",
    "        return\n",
    "    \n",
    "    def set_holding_cost(self, weights_new):\n",
    "        self.holding_cost += cp.sum(cp.multiply(self.holding_coeff, cp.neg(weights_new)))\n",
    "        return\n",
    "        \n",
    "    def calc_trans_cost(self, weights_new, weights_old, trans_coeff):\n",
    "        abs_trade= cp.abs(weights_new-weights_old)\n",
    "        return cp.sum(cp.multiply(trans_coeff, abs_trade))       \n",
    "    \n",
    "    \n",
    "    def set_trans_cost(self, weights_new, weights_old):\n",
    "        weights_curr= weights_new[:,0]\n",
    "        if weights_new.shape[1]>1:         \n",
    "            weights_future = weights_new[:,1:]\n",
    "            weights_future_shift = weights_new[:,:-1]\n",
    "            self.trans_cost = self.calc_trans_cost(weights_future, weights_future_shift, self.trans_coeff[:,1:])\n",
    "\n",
    "        self.trans_cost += self.calc_trans_cost(weights_curr, weights_old,self.trans_coeff[:,0])\n",
    "        return\n",
    "\n",
    "\n",
    "class Constraints:\n",
    "        #List of all constraints\n",
    "        def __init__(self, constr_list=['asset_limit_cardinality'], \n",
    "                     upper_limit=0.3, lower_limit=0.1, stock_limit=15):\n",
    "            self.upper_limit = upper_limit\n",
    "            self.lower_limit = lower_limit\n",
    "            self.stock_limit = stock_limit\n",
    "            self.constr_list = constr_list\n",
    "            self.value=[]\n",
    "\n",
    "        \n",
    "        def set_constraints(self, all_weights, y, cvar=False, gamma=None, z=None, r=None):\n",
    "            \n",
    "            # weights is without risk free\n",
    "            weights=all_weights[:-1,:]\n",
    "            \n",
    "            #unity condition\n",
    "            self.value += [cp.sum(all_weights,axis=0)==1]\n",
    "            \n",
    "            #can never be short cash\n",
    "            self.value += [all_weights[-1,:]>=0]\n",
    "            \n",
    "            num_stocks=len(weights)\n",
    "            \n",
    "            if cvar:\n",
    "                self.value += [z >= 0]\n",
    "                self.value += [z >= -r.T@all_weights-gamma]\n",
    "            \n",
    "            if \"no_short\" in self.constr_list:\n",
    "                self.value+=  [weights>=0]\n",
    "                \n",
    "            if \"asset_limit_cardinality\" in self.constr_list:\n",
    "                upper_limit= cp.multiply(self.upper_limit, y)\n",
    "                lower_limit = cp.multiply(self.lower_limit,y)\n",
    "                \n",
    "                #ensure that at least 1 but no more than 2 in each sector\n",
    "                for i in range(0,num_stocks,4):\n",
    "                    self.value += [y[i:i+3]>=1]\n",
    "                    self.value += [y[i:i+3]<=2]\n",
    "                    \n",
    "                self.value += [weights>=lower_limit, weights<=upper_limit]\n",
    "\n",
    "            elif \"asset_limit\" in self.constr_list:\n",
    "                self.value += [weights>=self.lower_limit, weights<=self.upper_limit]\n",
    "        \n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definitions Risk Type/ Optimization Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Risks:\n",
    "    def __init__(self, risk_type=\"MVO\", robust_type=\"ellip\", conf_lvl=0):\n",
    "        #risk value, return adjustment, risk type and confidence level\n",
    "        self.value=0\n",
    "        self.return_adj=0\n",
    "        self.risk_type=risk_type\n",
    "        self.robust_type=robust_type\n",
    "        self.conf_lvl=conf_lvl\n",
    "        return\n",
    "        \n",
    "    def set_risk(self, weights, Q, lookahead=1, S=5000, gamma=None, z=None, alpha=None):\n",
    "        \n",
    "        portfolio_risk=0\n",
    "        robustness_cost=0\n",
    "        num_stocks = weights.shape[1]\n",
    "        \n",
    "        if self.risk_type+= \"MVO\":\n",
    "        \n",
    "            for i in range(lookahead):\n",
    "                portfolio_risk += cp.quad_form(weights[:,i], Q[i])        \n",
    "            self.value = portfolio_risk\n",
    "            \n",
    "        elif self.risk_type == \"CVAR\":\n",
    "            if not S or not gamma or not z or not alpha:\n",
    "                print(\"Missing one of these required inputs for CVaR optimization: S, gamma, z, alpha\")\n",
    "                return\n",
    "            self.value = gamma + (1/((1-alpha)*S))*cp.sum(z)\n",
    "        \n",
    "        if self.robust_type == \"rect\":\n",
    "            \n",
    "            for i in range(lookahead):\n",
    "                delta = stats.norm.ppf(self.conf_lvl)*np.sqrt(np.diag(Q[i]/num_stocks))\n",
    "                robustness_cost += delta@cp.abs(weights[:,i])\n",
    "            self.return_adj= robustness_cost\n",
    "        \n",
    "        elif self.robust_type == \"ellip\":\n",
    "            \n",
    "            for i in range(lookahead):\n",
    "         \n",
    "                penalty = cp.norm(np.sqrt(np.diag(Q[i]/num_stocks))@weights[:,i],2)\n",
    "                robustness_cost += stats.chi2.ppf(self.conf_lvl, num_stocks)*penalty\n",
    "            self.return_adj = robustness_cost\n",
    "            \n",
    "    \n",
    "        return\n",
    "\n",
    "    def get_RP_objective(self, weights, args):\n",
    "        Q = args[0]\n",
    "        assets_risk_budget = args[1]\n",
    "        lookahead = args[2]\n",
    "        cost_model = args[3]\n",
    "        \n",
    "        num_stocks = len(assets_risk_budget)\n",
    "\n",
    "        self.value=0\n",
    "        # We convert the weights to a matrix\n",
    "        weights = np.matrix(weights)\n",
    "        for i in range(lookahead):\n",
    "            # We calculate the risk of the weights distribution\n",
    "\n",
    "            portfolio_risk = np.sqrt((weights[0,num_stocks*i:num_stocks*(i+1)] * Q[i] \n",
    "                                      * weights[0,num_stocks*i:num_stocks*(i+1)].T))[0, 0]\n",
    "\n",
    "            # We calculate the contribution of each asset to the risk of the weights\n",
    "            # distribution\n",
    "            assets_risk_contribution = np.multiply(weights[0,num_stocks*i:num_stocks*(i+1)].T, Q[i] \n",
    "                                                   * weights[0,num_stocks*i:num_stocks*(i+1)].T)/ portfolio_risk\n",
    "\n",
    "            # We calculate the desired contribution of each asset to the risk of the\n",
    "            # weights distribution\n",
    "            assets_risk_target = np.asmatrix(np.multiply(portfolio_risk, assets_risk_budget))\n",
    "\n",
    "            # Error between the desired contribution and the calculated contribution of\n",
    "            # each asset\n",
    "            self.value += np.sum(np.square(assets_risk_contribution - assets_risk_target.T))\n",
    "            \n",
    "            # Get the holding costs\n",
    "            self.value += np.sum(cost_model.holding_coeff[0,0]*weights[0,num_stocks*i:num_stocks*(i+1)])\n",
    "            \n",
    "            # Get the transaction costs\n",
    "            if i < lookahead-1:\n",
    "                abs_trade = np.abs(weights[0, num_stocks*i:num_stocks*(i+1)]-\n",
    "                                   weights[0, num_stocks*(i+1):num_stocks*(i+2)])\n",
    "                self.value += np.sum(cost_model.trans_coeff[0,0]*abs_trade)\n",
    "            \n",
    "        # It returns the calculated error\n",
    "        return self.value \n",
    "    \n",
    "    \n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, look_ahead, goal_ret):\n",
    "        self.opt_weights = 0\n",
    "        self.status = None\n",
    "        self.look_ahead=look_ahead\n",
    "        self.goal_ret=goal_ret\n",
    "        return\n",
    "        \n",
    "    def Solver(self, port, mu , Q, rf, constr_model, cost_model, risk_model, scen_model):\n",
    "        \n",
    "        mu_np = np.array(mu)\n",
    "        Q_np = np.array(Q)        \n",
    "        num_stocks = port.weights.shape[1]-1\n",
    "        num_simulations=5000\n",
    "        \n",
    "        if risk_model.risk_type ==\"CVAR\":\n",
    "            self.look_ahead=1\n",
    "            mu_np = np.array(mu)[0,:]\n",
    "            mu_np = np.expand_dims(mu_np, axis=0)\n",
    "        \n",
    "        \n",
    "        #Construct optimization problem\n",
    "        all_weights = cp.Variable((num_stocks+1,self.look_ahead))   \n",
    "        y = cp.Variable((num_stocks,self.look_ahead), boolean=True)\n",
    "        z = cp.Variable((num_simulations,1)) \n",
    "        g = cp.Variable(1) \n",
    "        \n",
    "        weights_prev= port.weights[-1,:-1]   \n",
    "        weights=all_weights[:-1,:]\n",
    "\n",
    "        # Set model parameters\n",
    "        cost_model.set_trans_cost(weights, weights_prev)\n",
    "        cost_model.set_holding_cost(weights)    \n",
    "        constr_model.set_constraints(all_weights, y)\n",
    "        scen_model.set_scenarios()\n",
    "        \n",
    "        if risk_model.risk_type==\"CVAR\":\n",
    "            constr_model.set_constraints(all_weights, y, cvar=True, gamma=g, z=z, r=scen_model.value)\n",
    "            risk_model.set_risk(weights, Q, S=5000, gamma=g, z=z, alpha=alpha)\n",
    "        elif risk_model.risk_type==\"MVO\":        \n",
    "            constr_model.set_constraints(all_weights, y)\n",
    "            risk_model.set_risk(weights, Q,look_ahead)\n",
    "\n",
    "        # Get portfolio return\n",
    "        portfolio_return_per_period = mu_np@weights\n",
    "        rf_return = cp.sum(rf*all_weights[-1,:])\n",
    "        portfolio_return = cp.trace(portfolio_return_per_period)+rf_return \n",
    "        \n",
    "        #Max return objective\n",
    "        #objective= cp.Maximize(portfolio_return-risk_model.return_adj)\n",
    "        \n",
    "        #Minimize risk objective\n",
    "        objective= cp.Minimize(risk_model.value)\n",
    "        constr_model.value+= [portfolio_return - risk_model.return_adj >=self.goal_ret]\n",
    "        \n",
    "        #Construct Problem and Solve\n",
    "        prob= cp.Problem(objective, constr_model.value)\n",
    "        result=prob.solve(solver=\"GUROBI\")\n",
    "        self.status= prob.status\n",
    "        if self.status == \"optimal\":\n",
    "            self.opt_weights=np.array(all_weights.value)[:,0]\n",
    "            print(\"port return:\",portfolio_return.value)\n",
    "            print(\"return_adj:\", risk_model.return_adj.value)\n",
    "            print(\"risk value:\",risk_model.value.value)\n",
    "            print(\"holding cost:\",cost_model.holding_cost.value)\n",
    "            print(\"trans cost:\", cost_model.trans_cost.value)\n",
    "    \n",
    "        else:\n",
    "            print(\"Unsolvable, use old weights\")\n",
    "            self.opt_weights=port.weights[-1].T\n",
    "     \n",
    "        return self.opt_weights\n",
    "    \n",
    "\n",
    "\n",
    "    def risk_parity(self, port, Q, lookahead, risk_model, cost_model):\n",
    "        TOLERANCE = 1e-7\n",
    "        Q_np =np.array(Q)\n",
    "        num_stocks=port.weights.shape[1]-1\n",
    "\n",
    "        #Construct optimization problem\n",
    "        init_weights = np.tile(port.weights[-1,:-1],lookahead).astype(float)\n",
    "        init_rf = port.weights[-1,-1]\n",
    "        weight_total = 1-init_rf\n",
    "        \n",
    "        if np.count_nonzero(init_weights)==0:\n",
    "            init_weights = np.array([1/num_stocks]*num_stocks*lookahead)\n",
    "            weight_total=1\n",
    "            init_rf = 0\n",
    "        \n",
    "        # The desired contribution of each asset to the portfolio risk: we want all\n",
    "        # assets to contribute equally\n",
    "        assets_risk_budget = [1/num_stocks] * num_stocks\n",
    "\n",
    "        # Optimisation process of weights\n",
    "        # Restrictions to consider in the optimisation: only long positions whose\n",
    "        # sum equals 100%\n",
    "        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - weight_total},\n",
    "                       {'type': 'ineq', 'fun': lambda x: x})\n",
    "\n",
    "        # Optimisation process in scipy\n",
    "        optimize_result = minimize(fun=risk_model.get_RP_objective,\n",
    "                                   x0=init_weights,\n",
    "                                   args=[Q, assets_risk_budget, lookahead, cost_model],\n",
    "                                   method='SLSQP',\n",
    "                                   constraints=constraints,\n",
    "                                   tol=TOLERANCE,\n",
    "                                   options={'disp': False, 'maxiter':5000}\n",
    "                                  )\n",
    "\n",
    "        # Recover the weights from the optimised object\n",
    "        weights = np.array(optimize_result.x) \n",
    "        \n",
    "        self.opt_weights = np.concatenate((weights[0:num_stocks], np.array([init_rf])))\n",
    "        return self.opt_weights        \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definitions Backtest/Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class Livetest:\n",
    "    def __init__(self, start_date, end_date, period='M'):\n",
    "        self.rebal_freq = period\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date        \n",
    "\n",
    "        return\n",
    "        \n",
    "    \n",
    "    def run(self, data, portfolio, factor_model, opt_model, constr_model, cost_model, risk_model):      \n",
    "        look_back= factor_model.lookback\n",
    "        look_ahead= factor_model.lookahead\n",
    "        stock_return= data.stock_returns      \n",
    "        reb_dates= np.array(data.stock_returns.loc[self.start_date:self.end_date].index)    \n",
    "        \n",
    "        \n",
    "        for t in reb_dates:\n",
    "            #need some dynamic adjustment here... how to set risk_model confidence level, cost_coefficieints,\n",
    "            #constraint asset limits, goal_return \n",
    "            \n",
    "            goal_return\n",
    "            \n",
    "            \n",
    "            mu, Q = factor_model.get_param_estimate(t, data)\n",
    "            new_rf_rate=float(data.risk_free.loc[t])            \n",
    "            \n",
    "            weights = opt_model.Solver(portfolio, mu , Q, new_rf_rate, self.lookahead,\n",
    "                                        constr_model, cost_model, risk_model)     \n",
    "            \n",
    "\n",
    "#             elif risk_model.risk_type == 'risk-parity':\n",
    "#                 weights = optimizer.risk_parity(portfolio, Q, self.lookahead, risk_model, cost_model)\n",
    "                \n",
    "\n",
    "                \n",
    "            portfolio.update_dates(t)\n",
    "            portfolio.update_weights(weights)\n",
    "            portfolio.update_returns(np.dot(weights[:-1],stock_return.loc[t])+weights[-1]*new_rf_rate)\n",
    "\n",
    "        return portfolio.get_Sharpe(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class Backtest:\n",
    "    def __init__(self, start_date, end_date, period='M'):\n",
    "        self.rebal_freq = period\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date        \n",
    "\n",
    "        return\n",
    "        \n",
    "    \n",
    "    def run(self, data, portfolio, factor_model, opt_model, constr_model, cost_model, risk_model):      \n",
    "        look_back= factor_model.lookback\n",
    "        look_ahead= factor_model.lookahead\n",
    "        stock_return= data.stock_returns      \n",
    "        reb_dates= np.array(data.stock_returns.loc[self.start_date:self.end_date].index)    \n",
    "        \n",
    "        \n",
    "        for t in reb_dates:\n",
    "            #need some dynamic adjustment here... how to set risk_model confidence level, cost_coefficieints,\n",
    "            #constraint asset limits, goal_return \n",
    "        \n",
    "            \n",
    "            \n",
    "            mu, Q = factor_model.get_param_estimate(t, data)\n",
    "            new_rf_rate=float(data.risk_free.loc[t])            \n",
    "            \n",
    "            weights = opt_model.Solver(portfolio, mu , Q, new_rf_rate, self.lookahead,\n",
    "                                        constr_model, cost_model, risk_model)     \n",
    "            \n",
    "\n",
    "#             elif risk_model.risk_type == 'risk-parity':\n",
    "#                 weights = optimizer.risk_parity(portfolio, Q, self.lookahead, risk_model, cost_model)\n",
    "                \n",
    "\n",
    "                \n",
    "            portfolio.update_dates(t)\n",
    "            portfolio.update_weights(weights)\n",
    "            portfolio.update_returns(np.dot(weights[:-1],stock_return.loc[t])+weights[-1]*new_rf_rate)\n",
    "\n",
    "        return portfolio.get_Sharpe(data)\n",
    "\n",
    "\n",
    "    def grid_search(self, data, portfolio, model, trans_coeff=0.2, hold_coeff=0.2, lam=0.9, conf_level=0.95):\n",
    "\n",
    "#         # Overall - currently test values are used\n",
    "#         pot_lookaheads = [1, 3, 6, 12, 60]\n",
    "#         pot_lookbacks = [2, 3, 6, 12, 60]\n",
    "\n",
    "#         # Factor Models\n",
    "#         factor_models = ['CAPM', 'FF', 'Carhart', 'PCA'] # Data\n",
    "#         regressions = ['linear', 'lasso', 'ridge', 'SVR'] # FactorModel\n",
    "\n",
    "#         # Constraints\n",
    "#         cardinalities = ['', 'cardinality']\n",
    "#         asset_limits = ['asset_limit_cardinality', 'asset_limit']\n",
    "#         no_shorts = ['', 'no_short']\n",
    "#         constraints_list = [cardinalities, asset_limits, no_shorts]\n",
    "\n",
    "#         stock_limits = list(range(5, 501, 5))\n",
    "\n",
    "#         # Optimization\n",
    "#         MVO_robustness = ['', 'rectangular', 'elliptical']\n",
    "\n",
    "        # Overall\n",
    "        pot_lookaheads = [5]\n",
    "        pot_lookbacks = [20]\n",
    "\n",
    "        # Factor Models\n",
    "        factor_models = ['FF', 'PCA']  # Data\n",
    "        weights = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1],[0.25,0.25,0.25,0.25],\n",
    "                       [0,0.5,0.5,0],[0,0.25,0.25,0.5],[0,0,0.5,0.5]]\n",
    "\n",
    "        # Constraints\n",
    "        cardinalities = ['cardinality']\n",
    "        asset_limits = ['asset_limit_cardinality', 'asset_limit']\n",
    "        no_shorts = ['no_short']\n",
    "        constraints_list = [cardinalities, asset_limits, no_shorts]\n",
    "\n",
    "        stock_limits = list(range(5, 21, 5))\n",
    "        upper_asset_limits = [1]\n",
    "        lower_asset_limits = [-1]\n",
    "\n",
    "        # Optimization\n",
    "        MVO_robustness = ['ellip']\n",
    "\n",
    "        # list of sharpe ratios per parameter combination\n",
    "        sharpe_ratios = []\n",
    "\n",
    "        # list of parameter combinations corresponding to sharpe ratio\n",
    "        parameter_combos = []\n",
    "\n",
    "        for combo in tqdm(list(itertools.product(factor_models, weights, \\\n",
    "                                                 list(itertools.product(*constraints_list)), stock_limits, \\\n",
    "                                                 upper_asset_limits, lower_asset_limits, MVO_robustness))):\n",
    "\n",
    "            # Store the combination\n",
    "            curr_combo = {'rebalance_freq': 'M', 'factor_model': combo[0], 'weights': combo[1],\n",
    "                          'constraints_list': list(combo[2]), 'stock_limit': combo[3], 'upper_asset_limit': combo[4],\n",
    "                          'lower_asset_limit': combo[5], 'robustness': combo[6]}\n",
    "\n",
    "            # Initial Setup\n",
    "            data.set_factor_returns(curr_combo['factor_model'], curr_combo['rebalance_freq'])\n",
    "\n",
    "            num_stocks = data.get_num_stocks()\n",
    "            cost_model = Costs(trans_coeff, hold_coeff)\n",
    "\n",
    "            # Get lookaheads that are multiples of the rebalancing frequency and <= 60 months\n",
    "            if curr_combo['rebalance_freq'] == 'M':\n",
    "                first = 1\n",
    "            else:\n",
    "                first = int(curr_combo['rebalance_freq'][0])\n",
    "\n",
    "            lookaheads = list(itertools.compress(pot_lookaheads, [look >= first for look in pot_lookaheads]))\n",
    "            lookbacks = list(itertools.compress(pot_lookbacks, [look >= first for look in pot_lookbacks]))\n",
    "\n",
    "            for lookahead in lookaheads:\n",
    "                curr_combo['lookahead'] = lookahead\n",
    "                for lookback in lookbacks:\n",
    "                    curr_combo['lookback'] = lookback\n",
    "\n",
    "                    # Continue Setup\n",
    "                    cost_model.replicate_cost_coeff(num_stocks, lookahead)\n",
    "                    constr_model = Constraints(curr_combo['constraints_list'])\n",
    "\n",
    "                    risk_model = Risks(curr_combo['robustness'], conf_level)\n",
    "\n",
    "                    # Run backtest\n",
    "                    factor = FactorModel(curr_combo['lookahead'], curr_combo['lookback'],\n",
    "                                         curr_combo['weights'])\n",
    "                    sharpe = self.run(data, portfolio, factor, model, constr_model, cost_model, risk_model)\n",
    "\n",
    "                    # Update results\n",
    "                    sharpe_ratios.append(sharpe)\n",
    "                    parameter_combos.append(curr_combo)\n",
    "\n",
    "        return sharpe_ratios, parameter_combos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorModel:\n",
    "    def __init__(self, lookahead, lookback, regress_weighting):\n",
    "        \n",
    "        \"\"\"\n",
    "        lookahead: number of periods in the future to estimate\n",
    "        lookback: number of periods in the past to use for estimations\n",
    "        regress_weighting: array of size 4 with weight corresponding to each regression type; adds up to 1; \n",
    "        order is linear, lasso, ridge, SVR; in the case where there is one 1 and the rest 0's, there is no ensembling;\n",
    "        can artifically call LSTM by setting all weights to 0\n",
    "        \"\"\"\n",
    "        self.lookahead = lookahead\n",
    "        self.lookback = lookback\n",
    "        self.regress_weighting = regress_weighting\n",
    "        return\n",
    "               \n",
    "    def get_param_estimate(self, rebal_date, data):\n",
    "               \n",
    "        if sum(self.regress_weighting) == 0:\n",
    "            return self.get_mu_LSTM(rebal_date, data)\n",
    "\n",
    "        elif sum(self.regress_weighting) == 1:\n",
    "            return self.get_mu_Q_regression(rebal_date, data)\n",
    "        \n",
    "        else:\n",
    "            return \"ERROR: This regression weighting is not valid. Please make sure the weights sum to 1. You can also give all zeros for LSTM.\"\n",
    "        \n",
    "    def get_mu_Q_regression(self, rebal_date, data): \n",
    "        returns_data = data.stock_returns\n",
    "        factor_data = data.factor_returns\n",
    "        lookahead = self.lookahead\n",
    "        lookback = self.lookback\n",
    "        regress_weighting = self.regress_weighting\n",
    "                \n",
    "        # For keeping track of mu's and Q's from each period\n",
    "        mu_arr = []\n",
    "        Q_arr = []\n",
    "\n",
    "        n_factors = len(factor_data.columns)\n",
    "\n",
    "        returns_data = data.get_lookback_data(returns_data, rebal_date, lookback)\n",
    "        factor_data = data.get_lookback_data(factor_data, rebal_date, lookback)\n",
    "        \n",
    "        for i in range(0, lookahead):\n",
    "\n",
    "            # Calculate the factor covariance matrix\n",
    "            F = factor_data.loc[:, factor_data.columns != 'Ones'].cov()\n",
    "\n",
    "            # Calculate the factor expected excess return from historical data using the geometric mean\n",
    "            factor_data['Ones'] = [1 for i in range(len(factor_data))]\n",
    "            gmean = stats.gmean(factor_data + 1,axis=0) - 1\n",
    "\n",
    "            # Set up X and Y to determine alpha and beta\n",
    "            X = factor_data\n",
    "            Y = returns_data\n",
    "            X = X.to_numpy()\n",
    "            Y = Y.to_numpy()\n",
    "\n",
    "            \n",
    "            ### LINEAR REGRESSION\n",
    "        \n",
    "            model = LinearRegression().fit(X,Y)\n",
    "            alpha = model.intercept_\n",
    "            beta = model.coef_[:,0:n_factors]\n",
    "\n",
    "            # Calculate the residuals \n",
    "            alpha = np.reshape(alpha,(alpha.size,1))\n",
    "            epsilon = returns_data.to_numpy() - np.matmul(X, np.transpose(np.hstack((beta, alpha))))\n",
    "\n",
    "            # Calculate the residual variance with \"N - p - 1\" degrees of freedom\n",
    "            sigmaEp = np.sum(epsilon**2, axis=0) / (len(returns_data) - n_factors - 1)\n",
    "\n",
    "            #  Calculate the asset expected excess returns\n",
    "            mu_linear = model.predict([gmean])[0]\n",
    "\n",
    "            # Calculate the diagonal matrix of residuals and the asset covariance matrix\n",
    "            D = np.diag(sigmaEp)\n",
    "\n",
    "            # Calculate the covariance matrix\n",
    "            Q_linear = np.matmul(np.matmul(beta,F.to_numpy()),beta.T)+D\n",
    "\n",
    "\n",
    "            ### LASSO REGRESSION\n",
    "\n",
    "            model = Lasso().fit(X,Y)\n",
    "            alpha = model.intercept_\n",
    "            beta = model.coef_[:,0:n_factors]\n",
    "\n",
    "            # Calculate the residuals \n",
    "            alpha = np.reshape(alpha,(alpha.size,1))\n",
    "            epsilon = returns_data.to_numpy() - np.matmul(X, np.transpose(np.hstack((beta, alpha))))\n",
    "\n",
    "            # Calculate the residual variance with \"N - p - 1\" degrees of freedom\n",
    "            sigmaEp = np.sum(epsilon**2, axis=0) / (len(returns_data) - n_factors - 1)\n",
    "\n",
    "            #  Calculate the asset expected excess returns\n",
    "            mu_lasso = model.predict([gmean])[0]\n",
    "\n",
    "            # Calculate the diagonal matrix of residuals and the asset covariance matrix\n",
    "            D = np.diag(sigmaEp)\n",
    "\n",
    "            # Calculate the covariance matrix\n",
    "            Q_lasso = np.matmul(np.matmul(beta,F.to_numpy()),beta.T)+D\n",
    "\n",
    "\n",
    "            ### RIDGE REGRESSION\n",
    "\n",
    "            model = Ridge().fit(X,Y)\n",
    "            alpha = model.intercept_\n",
    "            beta = model.coef_[:,0:n_factors]\n",
    "\n",
    "            # Calculate the residuals \n",
    "            alpha = np.reshape(alpha,(alpha.size,1))\n",
    "            epsilon = returns_data.to_numpy() - np.matmul(X, np.transpose(np.hstack((beta, alpha))))\n",
    "\n",
    "            # Calculate the residual variance with \"N - p - 1\" degrees of freedom\n",
    "            sigmaEp = np.sum(epsilon**2, axis=0) / (len(returns_data) - n_factors - 1)\n",
    "\n",
    "            #  Calculate the asset expected excess returns\n",
    "            mu_ridge = model.predict([gmean])[0]\n",
    "\n",
    "            # Calculate the diagonal matrix of residuals and the asset covariance matrix\n",
    "            D = np.diag(sigmaEp)\n",
    "\n",
    "            # Calculate the covariance matrix\n",
    "            Q_ridge = np.matmul(np.matmul(beta,F.to_numpy()),beta.T)+D\n",
    "\n",
    "\n",
    "            ### SUPPORT VECTOR REGRESSION\n",
    "\n",
    "            model = make_pipeline(StandardScaler(), MultiOutputRegressor(LinearSVR(C=1, dual=False, loss=\"squared_epsilon_insensitive\"))).fit(X, Y)\n",
    "            beta = np.array([[model.named_steps['multioutputregressor'].estimators_[i].coef_[0:n_factors] for i in range(len(model.named_steps['multioutputregressor'].estimators_))]])[0]\n",
    "            alpha = np.array([model.named_steps['multioutputregressor'].estimators_[i].intercept_[0] for i in range(len(model.named_steps['multioutputregressor'].estimators_))])\n",
    "\n",
    "            # Calculate the residuals \n",
    "            alpha = np.reshape(alpha,(alpha.size,1))\n",
    "            epsilon = returns_data.to_numpy() - np.matmul(X, np.transpose(np.hstack((beta, alpha))))\n",
    "\n",
    "            # Calculate the residual variance with \"N - p - 1\" degrees of freedom\n",
    "            sigmaEp = np.sum(epsilon**2, axis=0) / (len(returns_data) - n_factors - 1)\n",
    "\n",
    "            #  Calculate the asset expected excess returns\n",
    "            mu_SVR = model.predict([gmean])[0]\n",
    "\n",
    "            # Calculate the diagonal matrix of residuals and the asset covariance matrix\n",
    "            D = np.diag(sigmaEp)\n",
    "\n",
    "            # Calculate the covariance matrix\n",
    "            Q_SVR = np.matmul(np.matmul(beta,F.to_numpy()),beta.T)+D\n",
    "\n",
    "        \n",
    "            # Ensemble the methods\n",
    "            mu = regress_weighting[0]*mu_linear + regress_weighting[1]*mu_lasso + regress_weighting[2]*mu_ridge + regress_weighting[3]*mu_SVR\n",
    "            Q = regress_weighting[0]*Q_linear + regress_weighting[1]*Q_lasso + regress_weighting[2]*Q_ridge + regress_weighting[3]*Q_SVR\n",
    "\n",
    "            # Add mu and Q to array\n",
    "            mu_arr.append(mu)\n",
    "            Q_arr.append(Q)\n",
    "\n",
    "            # Update for next time step\n",
    "            factor_data = factor_data[1:]\n",
    "            factor_append = pd.Series(gmean, index = factor_data.columns)\n",
    "            factor_data = factor_data.append(factor_append, ignore_index=True)\n",
    "\n",
    "            returns_data = returns_data[1:]\n",
    "            mu_append = pd.Series(mu, index=returns_data.columns)\n",
    "            returns_data = returns_data.append(mu_append, ignore_index=True)   \n",
    "\n",
    "        return mu_arr, Q_arr\n",
    "        \n",
    "    def get_mu_LSTM(self, rebal_date, data): \n",
    "        returns_data = data.stock_returns\n",
    "        factor_data = data.factor_returns\n",
    "        \n",
    "        lookahead = self.lookahead\n",
    "        lookback = self.lookback\n",
    "        regress_weighting = self.regress_weighting\n",
    "\n",
    "        returns_data = data.get_lookback_data(returns_data, rebal_date, lookback)\n",
    "        factor_data = data.get_lookback_data(factor_data, rebal_date, lookback)\n",
    "        \n",
    "        tempx, tempy = self.generate_X_y(factor_data.values, returns_data.values, lookback, lookahead)\n",
    "        train_x, test_x, train_y, test_y = self.traintest_split(tempx, tempy)\n",
    "\n",
    "        # scale inputs\n",
    "        scaled_train_x = (train_x - train_x.min())/(train_x.max() - train_x.min())\n",
    "        scaled_test_x = (test_x - test_x.min())/(test_x.max() - test_x.min())\n",
    "        scaled_train_y = (train_y - train_y.min())/(train_y.max() - train_y.min())\n",
    "        scaled_test_y = (test_y - test_y.min())/(test_y.max() - test_y.min())\n",
    "\n",
    "        mu = self.get_prediction(train_x, train_y, factor_data, lookback)\n",
    "        return mu\n",
    "    \n",
    "    def generate_X_y(self, factor_data, returns_data, n_lookback, n_lookforward):\n",
    "        X, y = list(), list()\n",
    "        in_start = 0\n",
    "        for i in range(len(factor_data)):\n",
    "            in_end = in_start + n_lookback\n",
    "            out_end = in_end + n_lookforward\n",
    "            # ensure we have enough data for this instance\n",
    "            if out_end <= len(factor_data):\n",
    "                X.append(factor_data[in_start:in_end,:])\n",
    "                y.append(returns_data[in_end:out_end,:])\n",
    "            in_start += 1\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def traintest_split(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test   \n",
    "    \n",
    "    def build_model(self, train_x, train_y):\n",
    "        # define parameters\n",
    "        verbose, epochs, batch_size = 0, 50, 16\n",
    "        n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "        model.add(RepeatVector(n_outputs))\n",
    "        model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "        model.add(TimeDistributed(Dense(train_y.shape[2])))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "        # fit network\n",
    "        model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        return model\n",
    "    \n",
    "    def forecast(self, model, history, n_lookback):\n",
    "        # flatten data\n",
    "        data = np.array(history)\n",
    "        data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "        # retrieve last observations for lookback data\n",
    "        input_x = data[-n_lookback:, :]\n",
    "        # reshape into [1, n_lookback, n]\n",
    "        input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "        # forecast the next set\n",
    "        yhat = model.predict(input_x, verbose=0)\n",
    "        # we only want the vector forecast\n",
    "        yhat = yhat[0]\n",
    "        return yhat\n",
    "\n",
    "    def evaluate_forecasts(self, actual, predicted):\n",
    "        # calculate overall RMSE\n",
    "        s = 0\n",
    "        for row in range(actual.shape[0]):\n",
    "            for col in range(actual.shape[1]):\n",
    "                for k in range(actual.shape[2]):\n",
    "                    s += (actual[row, col, k] - predicted[row, col, k])**2\n",
    "        score = sqrt(s / (actual.shape[0] * actual.shape[1] * actual.shape[2]))\n",
    "        return score\n",
    "\n",
    "    def evaluate_model(self, train_x, train_y, test_x, test_y, n_lookback):\n",
    "        # fit model\n",
    "        model = self.build_model(train_x, train_y)\n",
    "        history = [x for x in train_x]\n",
    "        # walk-forward validation \n",
    "        predictions = list()\n",
    "        for i in range(len(test_x)):\n",
    "            yhat_sequence = self.forecast(model, history, n_lookback)\n",
    "            # store the predictions\n",
    "            predictions.append(yhat_sequence)\n",
    "            # get real observation and add to history for predicting the next set\n",
    "            history.append(test_x[i, :])\n",
    "        # evaluate predictions \n",
    "        predictions = np.array(predictions)\n",
    "        score = self.evaluate_forecasts(test_y, predictions)\n",
    "        plt.plot(model.history.history['loss'])\n",
    "        #plt.plot(model.history.history['val_loss'])\n",
    "        return score\n",
    "    \n",
    "    def get_prediction(self, train_x, train_y, factor_data, lookback):\n",
    "        model = self.build_model(train_x, train_y)\n",
    "        return self.forecast(model, factor_data.tail(lookback), lookback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class Regime:\n",
    "    def __init__(self, data ,t):\n",
    "        train_prices=None\n",
    "        train_returns=None\n",
    "        train_dates=None\n",
    "        self.get_train_data(data,t)\n",
    "\n",
    "    def get_train_data(self, data, t):\n",
    "        mkt_data = data.factor_returns[\"Mkt-RF\"]+data_set.factor_returns[\"RF\"]\n",
    "        first_date=\"2010-01-01\"\n",
    "        mkt_returns=mkt_data[first_date:t]\n",
    "        self.train_dates=mkt_returns.index\n",
    "\n",
    "        mkt_returns=np.array(mkt_returns.values)\n",
    "        mkt_prices = 100*(np.array([x+1 for x in mkt_returns]).cumprod())\n",
    "        mkt_prices=np.expand_dims(mkt_prices,axis=1)\n",
    "        mkt_returns=np.expand_dims(mkt_returns,axis=1)\n",
    "        self.train_prices=mkt_prices\n",
    "        self.train_returns=mkt_returns\n",
    "\n",
    "\n",
    "    def HMM (self, num_hs):\n",
    "        model=hmm.GaussianHMM(n_components=num_hs)\n",
    "        model.fit(self.train_returns)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"2019-12-31\"\n",
    "reg=Regime(data_set,t)\n",
    "reg_model =reg.HMM(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=reg_model.predict(reg.train_returns)\n",
    "test=np.array(list(map(bool,out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative Return')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.scatter(reg.train_dates[test],reg.train_prices[test])\n",
    "        plt.scatter(reg.train_dates[~test],reg.train_prices[~test])\n",
    "\n",
    "        plt.xticks(rotation=45)\n",
    "        #plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Cumulative Return\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
