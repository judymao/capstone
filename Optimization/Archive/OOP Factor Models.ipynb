{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.optimize as sco\n",
    "import numpy as np\n",
    "import pandas_datareader as web\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as smf\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class factor_model:\n",
    "    def __init__(self, data, lookahead, lookback, model_type=\"Linear\"):\n",
    "        self.returns_data = data.returns_data\n",
    "        self.factor_data = data.factor_data\n",
    "        self.lookahead = lookahead\n",
    "        self.lookback = lookback\n",
    "        self.model_type = model_type\n",
    "               \n",
    "    def get_param_estimate(self):\n",
    "               \n",
    "        if model_type == \"LSTM\":\n",
    "            return self.get_mu_LSTM()\n",
    "\n",
    "        elif model_type == \"Linear\" or model_type == \"Lasso\" or model_type == \"Ridge\" or model_type == \"SVR\":\n",
    "            return self.get_mu_Q_regression()\n",
    "        \n",
    "        else:\n",
    "            return \"ERROR: This factor model type has not been implemented. Please input one of the following: LSTM, Linear, Lasso, Ridge, SVR.\"\n",
    "        \n",
    "    def get_mu_Q_regression(self): \n",
    "        returns_data = self.returns_data\n",
    "        factor_data = self.factor_data\n",
    "        lookahead = self.lookahead\n",
    "        lookback = self.lookback\n",
    "        regress_type = self.model_type\n",
    "        \n",
    "        # For keeping track of mu's and Q's from each period\n",
    "        mu_arr = []\n",
    "        Q_arr = []\n",
    "\n",
    "        n_factors = len(factor_data.columns)\n",
    "        factor_data = factor_data.tail(lookback)\n",
    "        returns_data = returns_data.tail(lookback)\n",
    "\n",
    "        for i in range(0, lookahead):\n",
    "\n",
    "            # Calculate the factor covariance matrix\n",
    "            F = factor_data.loc[:, factor_data.columns != 'Ones'].cov()\n",
    "\n",
    "            # Calculate the factor expected excess return from historical data using the geometric mean\n",
    "            factor_data['Ones'] = [1 for i in range(len(factor_data))]\n",
    "            gmean = stats.gmean(factor_data + 1,axis=0) - 1\n",
    "\n",
    "            # Set up X and Y to determine alpha and beta\n",
    "            X = factor_data\n",
    "            Y = returns_data\n",
    "            X = X.to_numpy()\n",
    "            Y = Y.to_numpy()\n",
    "\n",
    "           # Determine alpha and beta\n",
    "            if regress_type==\"Linear\":\n",
    "                model = LinearRegression().fit(X,Y)\n",
    "                alpha = model.intercept_\n",
    "                beta = model.coef_[:,0:n_factors]\n",
    "            elif regress_type==\"Lasso\":\n",
    "                model = Lasso().fit(X,Y)\n",
    "                alpha = model.intercept_\n",
    "                beta = model.coef_[:,0:n_factors]\n",
    "            elif regress_type==\"Ridge\":\n",
    "                model = Ridge().fit(X,Y)\n",
    "                alpha = model.intercept_\n",
    "                beta = model.coef_[:,0:n_factors]\n",
    "            elif regress_type==\"SVR\":           \n",
    "                model = make_pipeline(StandardScaler(), MultiOutputRegressor(LinearSVR(C=1, dual=False, loss=\"squared_epsilon_insensitive\"))).fit(X, Y)\n",
    "                beta = np.array([[model.named_steps['multioutputregressor'].estimators_[i].coef_[0:n_factors] for i in range(len(model.named_steps['multioutputregressor'].estimators_))]])[0]\n",
    "                alpha = np.array([model.named_steps['multioutputregressor'].estimators_[i].intercept_[0] for i in range(len(model.named_steps['multioutputregressor'].estimators_))])\n",
    "      \n",
    "\n",
    "            # Calculate the residuals \n",
    "            alpha = np.reshape(alpha,(alpha.size,1))\n",
    "            epsilon = returns_data.to_numpy() - np.matmul(X, np.transpose(np.hstack((beta, alpha))))\n",
    "\n",
    "            # Calculate the residual variance with \"N - p - 1\" degrees of freedom\n",
    "            p = 3\n",
    "            sigmaEp = np.sum(epsilon**2, axis=0) / (len(returns_data) - 1 - p)\n",
    "\n",
    "            #  Calculate the asset expected excess returns\n",
    "            mu = model.predict([gmean])[0]\n",
    "\n",
    "            # Calculate the diagonal matrix of residuals and the asset covariance matrix\n",
    "            D = np.diag(sigmaEp)\n",
    "\n",
    "            # Calculate the covariance matrix\n",
    "            Q = np.matmul(np.matmul(beta,F.to_numpy()),beta.T)+D\n",
    "\n",
    "            # Add mu and Q to array\n",
    "            mu_arr.append(mu)\n",
    "            Q_arr.append(Q)\n",
    "\n",
    "            # Update for next time step\n",
    "            factor_data = factor_data[1:]\n",
    "            factor_append = pd.Series(gmean, index = factor_data.columns)\n",
    "            factor_data = factor_data.append(factor_append, ignore_index=True)\n",
    "\n",
    "            returns_data = returns_data[1:]\n",
    "            mu_append = pd.Series(mu, index=returns_data.columns)\n",
    "            returns_data = returns_data.append(mu_append, ignore_index=True)   \n",
    "\n",
    "        return mu_arr, Q_arr\n",
    "        \n",
    "        \n",
    "    def get_mu_LSTM(self): \n",
    "        returns_data = self.returns_data\n",
    "        factor_data = self.factor_data\n",
    "        lookahead = self.lookahead\n",
    "        lookback = self.lookback\n",
    "        regress_type = self.model_type\n",
    "        \n",
    "        tempx, tempy = self.generate_X_y(factor_data.values, returns_data.values, lookback, lookahead)\n",
    "        train_x, test_x, train_y, test_y = self.traintest_split(tempx, tempy)\n",
    "\n",
    "        # scale inputs\n",
    "        scaled_train_x = (train_x - train_x.min())/(train_x.max() - train_x.min())\n",
    "        scaled_test_x = (test_x - test_x.min())/(test_x.max() - test_x.min())\n",
    "        scaled_train_y = (train_y - train_y.min())/(train_y.max() - train_y.min())\n",
    "        scaled_test_y = (test_y - test_y.min())/(test_y.max() - test_y.min())\n",
    "\n",
    "        mu = self.get_prediction(train_x, train_y, factor_data, lookback)\n",
    "        return mu\n",
    "    \n",
    "    def generate_X_y(self, factor_data, returns_data, n_lookback, n_lookforward):\n",
    "        X, y = list(), list()\n",
    "        in_start = 0\n",
    "        for i in range(len(factor_data)):\n",
    "            in_end = in_start + n_lookback\n",
    "            out_end = in_end + n_lookforward\n",
    "            # ensure we have enough data for this instance\n",
    "            if out_end <= len(factor_data):\n",
    "                X.append(factor_data[in_start:in_end,:])\n",
    "                y.append(returns_data[in_end:out_end,:])\n",
    "            in_start += 1\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def traintest_split(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test   \n",
    "    \n",
    "    def build_model(self, train_x, train_y):\n",
    "        # define parameters\n",
    "        verbose, epochs, batch_size = 0, 50, 16\n",
    "        n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "        model.add(RepeatVector(n_outputs))\n",
    "        model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "        model.add(TimeDistributed(Dense(train_y.shape[2])))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "        # fit network\n",
    "        model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        return model\n",
    "    \n",
    "    def forecast(self, model, history, n_lookback):\n",
    "        # flatten data\n",
    "        data = np.array(history)\n",
    "        data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "        # retrieve last observations for lookback data\n",
    "        input_x = data[-n_lookback:, :]\n",
    "        # reshape into [1, n_lookback, n]\n",
    "        input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "        # forecast the next set\n",
    "        yhat = model.predict(input_x, verbose=0)\n",
    "        # we only want the vector forecast\n",
    "        yhat = yhat[0]\n",
    "        return yhat\n",
    "\n",
    "    def evaluate_forecasts(self, actual, predicted):\n",
    "        # calculate overall RMSE\n",
    "        s = 0\n",
    "        for row in range(actual.shape[0]):\n",
    "            for col in range(actual.shape[1]):\n",
    "                for k in range(actual.shape[2]):\n",
    "                    s += (actual[row, col, k] - predicted[row, col, k])**2\n",
    "        score = sqrt(s / (actual.shape[0] * actual.shape[1] * actual.shape[2]))\n",
    "        return score\n",
    "\n",
    "    def evaluate_model(self, train_x, train_y, test_x, test_y, n_lookback):\n",
    "        # fit model\n",
    "        model = self.build_model(train_x, train_y)\n",
    "        history = [x for x in train_x]\n",
    "        # walk-forward validation \n",
    "        predictions = list()\n",
    "        for i in range(len(test_x)):\n",
    "            yhat_sequence = self.forecast(model, history, n_lookback)\n",
    "            # store the predictions\n",
    "            predictions.append(yhat_sequence)\n",
    "            # get real observation and add to history for predicting the next set\n",
    "            history.append(test_x[i, :])\n",
    "        # evaluate predictions \n",
    "        predictions = np.array(predictions)\n",
    "        score = self.evaluate_forecasts(test_y, predictions)\n",
    "        plt.plot(model.history.history['loss'])\n",
    "        #plt.plot(model.history.history['val_loss'])\n",
    "        return score\n",
    "    \n",
    "    def get_prediction(self, train_x, train_y, factor_data, lookback):\n",
    "        model = self.build_model(train_x, train_y)\n",
    "        return self.forecast(model, factor_data.tail(lookback), lookback)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
